# Complete Solution: Fix Visualization Rendering in Chat

## Problem Summary

Visualizations generated by tools (heatmap, shot map, pass network) are not rendering in the chat UI despite being correctly generated by the tools.

### Root Cause

**AgentScope's ReActAgent doesn't propagate tool response data (ImageBlocks and metadata) to the final reply message.**

The data flow breaks at this step:
```
[Viz Tool] → ToolResponse(ImageBlock + metadata) → [ReActAgent] ❌ → reply_msg (no images)
```

## Evidence

### ✅ What Works

1. **Tool Implementation** (agentspace/agent_tools/viz.py:193-199)
   ```python
   return ToolResponse(
       content=[
           TextBlock(type="text", text="\n".join(lines)),
           image_block,  # ✅ ImageBlock with base64 data
       ],
       metadata={
           "image_path": str(result.path),
           "image_data": image_meta.get("data"),  # ✅ base64 data
           "images": [image_meta],  # ✅ image metadata array
           "viz_type": "event_heatmap",
       }
   )
   ```

2. **Backend Extraction Logic** (agentspace/api/app.py)
   - `_attachments_from_msg()` (lines 100-136): Extracts ImageBlocks from `reply_msg.content`
   - Used at line 468: `attachments = _attachments_from_msg(reply_msg)`

3. **Frontend Extraction Logic** (frontend/components/ChatPanel.tsx)
   - `convertResponseAttachments()` (lines 96-141): Processes `data.attachments`
   - `extractAttachments()` (lines 143-226): Extracts from `data.metadata`
   - `mergeAttachments()` (lines 228-245): Combines both sources
   - Used at lines 528-530 to extract from both paths

4. **UI Rendering** (frontend/components/MessageBubble.tsx:42)
   ```tsx
   {hasAttachments && <VisualizationGallery attachments={attachments} />}
   ```

### ❌ What's Broken

**ReActAgent** (between tool execution and reply):
- Doesn't copy ImageBlocks from `ToolResponse.content` to `reply_msg.content`
- Doesn't merge `ToolResponse.metadata` into `reply_msg.metadata`

## Complete Solution Path

### Solution Overview

**Post-Reply Metadata Extraction Pattern**

After `agent.reply()` completes, inspect `agent.memory` to find recent tool executions, extract visualization data, and merge it into the reply message.

### Implementation Strategy

#### Option A: Memory-Based Extraction (Recommended)

**Advantages:**
- Least invasive
- No AgentScope internals modification
- Works with existing code
- Easy to test and debug

**Location:** agentspace/api/app.py:444-474 (`agent_chat` endpoint)

#### Implementation Steps

**Step 1: Create Helper Function**

Add to `agentspace/api/app.py` (around line 137, after `_attachments_from_msg`):

```python
async def _extract_tool_visualizations_from_memory(
    agent: ReActAgent,
    max_lookback: int = 10
) -> tuple[list[dict[str, Any]], dict[str, Any]]:
    """
    Extract visualization data from recent tool executions in agent memory.

    Returns:
        Tuple of (attachments_list, merged_metadata_dict)
    """
    from agentscope.message import ImageBlock

    attachments: list[dict[str, Any]] = []
    merged_metadata: dict[str, Any] = {}
    seen_images: set[str] = set()

    try:
        # Get recent memory to find tool responses
        history = await agent.memory.get_memory()

        # Look at last N messages for tool responses
        recent_messages = history[-max_lookback:] if len(history) > max_lookback else history

        for msg in reversed(recent_messages):
            # Check if this is a tool response message
            msg_role = getattr(msg, 'role', None)
            if msg_role not in ('assistant', 'tool', 'function'):
                continue

            # Extract from message content (ImageBlocks)
            msg_content = getattr(msg, 'content', [])
            if isinstance(msg_content, list):
                for block in msg_content:
                    if not isinstance(block, (dict, Mapping)):
                        continue
                    if block.get('type') == 'image':
                        source = block.get('source')
                        if isinstance(source, dict) and source.get('type') == 'base64':
                            data = source.get('data')
                            mime_type = source.get('media_type', 'image/png')
                            alt = block.get('alt')

                            if data and isinstance(data, str):
                                src = f"data:{mime_type};base64,{data}"
                                if src not in seen_images:
                                    seen_images.add(src)
                                    attachments.append({
                                        'type': 'image',
                                        'src': src,
                                        'mime_type': mime_type,
                                        'alt': alt,
                                    })

            # Extract from message metadata
            msg_metadata = getattr(msg, 'metadata', None)
            if isinstance(msg_metadata, dict):
                # Check for visualization markers
                viz_type = msg_metadata.get('viz_type')
                if viz_type:
                    # This is a visualization tool response
                    merged_metadata['viz_type'] = viz_type

                    # Extract image_data
                    if 'image_data' in msg_metadata:
                        merged_metadata['image_data'] = msg_metadata['image_data']
                    if 'image_path' in msg_metadata:
                        merged_metadata['image_path'] = msg_metadata['image_path']
                    if 'image_mime_type' in msg_metadata:
                        merged_metadata['image_mime_type'] = msg_metadata['image_mime_type']

                    # Extract images array
                    if 'images' in msg_metadata and isinstance(msg_metadata['images'], list):
                        for img_meta in msg_metadata['images']:
                            if isinstance(img_meta, dict):
                                data = img_meta.get('data')
                                mime_type = img_meta.get('mime_type', 'image/png')
                                alt = img_meta.get('alt')

                                if data and isinstance(data, str):
                                    src = f"data:{mime_type};base64,{data}"
                                    if src not in seen_images:
                                        seen_images.add(src)
                                        attachments.append({
                                            'type': 'image',
                                            'src': src,
                                            'mime_type': mime_type,
                                            'alt': alt,
                                        })

                    # Merge other relevant metadata
                    for key in ['match_id', 'team_name', 'opponent_name', 'competition_id',
                                'season_id', 'sample_size', 'total_shots', 'total_goals']:
                        if key in msg_metadata:
                            merged_metadata[key] = msg_metadata[key]

                    # Found visualization data, no need to look further back
                    break

    except Exception as exc:
        # Log but don't fail the request
        print(f"Warning: Failed to extract tool visualizations: {exc}")

    return attachments, merged_metadata
```

**Step 2: Update `agent_chat` Endpoint**

Modify `agentspace/api/app.py:444-474`:

```python
@app.post("/api/agent/chat", response_model=ChatResponse)
async def agent_chat(request: ChatRequest) -> ChatResponse:
    session_id = request.session_id or str(uuid4())
    agent = _get_or_create_agent(session_id, request.persona)
    lock = _get_session_lock(session_id)

    prompt = request.message.strip()
    context_text = _format_context_for_prompt(request.team_context)
    if context_text:
        prompt = f"{context_text}\n\nUser question:\n{prompt}"

    metadata = _metadata_from_team_context(request.team_context)

    async with lock:
        reply_msg = await agent.reply(
            Msg(
                name="user",
                role="user",
                content=prompt,
                metadata=metadata,
            )
        )

        # ✨ NEW: Extract visualization data from agent memory
        tool_attachments, tool_metadata = await _extract_tool_visualizations_from_memory(agent)

    reply_text = reply_msg.get_text_content() or ""

    # Extract attachments from reply message (existing logic)
    msg_attachments = _attachments_from_msg(reply_msg)

    # ✨ NEW: Merge tool attachments with message attachments
    all_attachments = msg_attachments + tool_attachments

    # ✨ NEW: Merge tool metadata with reply metadata
    final_metadata = {**(reply_msg.metadata or {}), **tool_metadata}
    if metadata:  # Include team context metadata
        final_metadata.update(metadata)

    return ChatResponse(
        session_id=session_id,
        reply=reply_text,
        metadata=final_metadata if final_metadata else None,
        attachments=all_attachments if all_attachments else None,
    )
```

**Step 3: Add Import**

At the top of `agentspace/api/app.py` (around line 10):

```python
from collections.abc import Mapping
```

(This is already imported, so no change needed)

**Step 4: Testing**

Create test file `tests/test_viz_rendering.py`:

```python
"""Test visualization rendering in chat."""
from unittest.mock import AsyncMock, MagicMock
import pytest
from agentscope.message import Msg, ImageBlock, Base64Source, TextBlock

from agentspace.api.app import _extract_tool_visualizations_from_memory


@pytest.mark.asyncio
async def test_extract_tool_visualizations_from_memory():
    """Test extraction of visualization data from agent memory."""
    # Mock agent with memory containing tool response
    agent = MagicMock()

    # Create a mock tool response message with ImageBlock
    tool_msg = Msg(
        name="tool",
        role="assistant",
        content=[
            TextBlock(type="text", text="Created heatmap."),
            ImageBlock(
                type="image",
                source=Base64Source(
                    type="base64",
                    media_type="image/png",
                    data="iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==",
                ),
                alt="Test heatmap",
            ),
        ],
        metadata={
            "viz_type": "event_heatmap",
            "image_data": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==",
            "image_path": "/tmp/heatmap.png",
            "team_name": "Arsenal",
            "match_id": 12345,
        },
    )

    # Mock memory
    agent.memory.get_memory = AsyncMock(return_value=[tool_msg])

    # Extract
    attachments, metadata = await _extract_tool_visualizations_from_memory(agent)

    # Verify
    assert len(attachments) == 1
    assert attachments[0]["type"] == "image"
    assert attachments[0]["src"].startswith("data:image/png;base64,")
    assert attachments[0]["alt"] == "Test heatmap"

    assert metadata["viz_type"] == "event_heatmap"
    assert metadata["team_name"] == "Arsenal"
    assert metadata["match_id"] == 12345
```

### Alternative Solution: Custom Agent Subclass

If memory extraction proves unreliable, create a custom agent:

**Location:** Create `agentspace/agents/viz_react_agent.py`:

```python
"""Custom ReActAgent that preserves tool visualization data."""
from typing import Any
from agentscope.agent import ReActAgent
from agentscope.message import Msg


class VizReActAgent(ReActAgent):
    """ReActAgent that preserves visualization data from tool responses."""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._last_tool_responses = []

    async def reply(self, msg: Msg) -> Msg:
        """Reply with visualization data preserved."""
        # Clear previous tool responses
        self._last_tool_responses = []

        # Call parent reply
        result = await super().reply(msg)

        # Extract visualization data from recent tool executions
        try:
            history = await self.memory.get_memory()
            for hist_msg in reversed(history[-10:]):
                msg_metadata = getattr(hist_msg, 'metadata', None)
                if isinstance(msg_metadata, dict) and msg_metadata.get('viz_type'):
                    # Found visualization tool response
                    # Merge into result metadata
                    if result.metadata is None:
                        result.metadata = {}
                    result.metadata.update(msg_metadata)

                    # Copy ImageBlocks to result content
                    msg_content = getattr(hist_msg, 'content', [])
                    if isinstance(msg_content, list):
                        result_content = getattr(result, 'content', [])
                        if not isinstance(result_content, list):
                            result_content = []
                        for block in msg_content:
                            if isinstance(block, dict) and block.get('type') == 'image':
                                result_content.append(block)
                        result.content = result_content
                    break
        except Exception as exc:
            # Don't fail reply on extraction error
            print(f"Warning: Failed to extract viz data: {exc}")

        return result
```

Then update `agentspace/agents/statsbomb_chat.py`:

```python
from .viz_react_agent import VizReActAgent

def build_chat_agent(...) -> VizReActAgent:  # Changed return type
    # ... existing code ...

    return VizReActAgent(  # Changed from ReActAgent
        name="statsbomb-analyst",
        sys_prompt=_system_prompt(),
        model=chat_model,
        formatter=formatter,
        toolkit=toolkit,
        plan_notebook=plan_notebook,
        max_iters=6,
    )
```

## Testing Plan

### Unit Tests

1. **Test memory extraction** (as shown above)
2. **Test attachment merging**
3. **Test metadata merging**

### Integration Tests

```python
@pytest.mark.asyncio
async def test_heatmap_renders_in_chat(test_client):
    """End-to-end test that heatmap appears in chat response."""
    response = await test_client.post("/api/agent/chat", json={
        "persona": "Analyst",
        "message": "Show me a heatmap for Arsenal in match 3869151",
    })

    data = response.json()
    assert response.status_code == 200
    assert data["attachments"] is not None
    assert len(data["attachments"]) > 0
    assert data["attachments"][0]["type"] == "image"
    assert "heatmap" in data["metadata"].get("viz_type", "").lower()
```

### Manual Testing

1. Start backend: `uvicorn agentspace.api.app:app --reload`
2. Start frontend: `cd frontend && npm run dev`
3. Ask: *"Show me a heatmap for Arsenal vs Chelsea match 3869151"*
4. Verify image appears in chat

## Migration Path

### Phase 1: Minimal Changes (1-2 hours)
- Implement `_extract_tool_visualizations_from_memory()`
- Update `agent_chat` endpoint
- Basic testing

### Phase 2: Robust Testing (2-3 hours)
- Unit tests for extraction
- Integration tests
- Edge case handling

### Phase 3: Optional Enhancements (1-2 hours)
- Implement `VizReActAgent` as fallback
- Add visualization caching
- Performance optimization

## Rollback Plan

If solution causes issues:

1. **Immediate**: Comment out memory extraction code
2. **Temporary**: Return empty attachments/metadata
3. **Long-term**: Implement feature flag for viz extraction

## Success Metrics

✅ Heatmaps render in chat UI
✅ Shot maps render in chat UI
✅ Pass networks render in chat UI
✅ No performance degradation
✅ All existing tests pass

## Additional Notes

### Why Not Modify AgentScope?

- External dependency
- Harder to maintain
- Solution works with standard AgentScope

### Why Memory Extraction?

- AgentScope stores all messages in memory
- Tool responses are in memory but not in final reply
- Memory is accessible via public API
- Non-invasive solution

### Future Improvements

1. **Cache tool responses** in session for faster retrieval
2. **Stream visualizations** as they're generated
3. **Support multiple visualizations** per response
4. **Add visualization metadata** to frontend for better UX

## References

- Tool implementation: `agentspace/agent_tools/viz.py`
- Backend API: `agentspace/api/app.py`
- Frontend chat: `frontend/components/ChatPanel.tsx`
- Frontend display: `frontend/components/MessageBubble.tsx`
- Test examples: `tests/test_viz_tools.py`
